{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89e5124e",
   "metadata": {},
   "source": [
    "https://vijaykumarkartha.medium.com/self-reflecting-ai-agents-using-langchain-d3a93684da92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c673df",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2405.06682"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed4501e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4a56864",
   "metadata": {},
   "source": [
    "## Lab: Answer and Reflection Module with OpenAI Chat API\n",
    "\n",
    "### Objective\n",
    "\n",
    "By the end of this lab, you will:\n",
    "\n",
    "1. Implement a basic Q\\&A function that prompts the OpenAI Chat API using a step-by-step chain-of-thought system message.\n",
    "2. Extend the module with a reflection step that analyzes the initial answer and improves the original question.\n",
    "3. Compare the original and improved questions and observe how refinement affects answer quality.\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* Python 3.8+\n",
    "* OpenAI Python client library installed (`pip install openai`)\n",
    "* API key set in your environment (`export OPENAI_API_KEY=\"your_key\"`)\n",
    "\n",
    "### 1. Setup\n",
    "\n",
    "```python\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\\ nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Basic answer function using chain-of-thought prompt\n",
    "def get_answer(question: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that thinks step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{question}\\nLet's think step by step.\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "```\n",
    "\n",
    "### 2. Test the Answer Module\n",
    "\n",
    "```python\n",
    "question = \"What is the capital of France and why is it significant in European history?\"\n",
    "answer = get_answer(question)\n",
    "print(\"Original Answer:\\n\", answer)\n",
    "```\n",
    "\n",
    "> **Observation:** Note length, depth, and clarity of the answer.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Reflection Module\n",
    "\n",
    "Now, implement a reflection step to refine the question based on the answer.\n",
    "\n",
    "```python\n",
    "\n",
    "def reflect_and_improve(question: str, answer: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    reflect_prompt = (\n",
    "        f\"I asked: \\\"{question}\\\" and got this answer: \\\"{answer}\\\". \"\n",
    "        \"Suggest a clearer or more specific version of my question to get an even better answer.\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that improves user questions.\"},\n",
    "        {\"role\": \"user\", \"content\": reflect_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "```\n",
    "\n",
    "### 4. Test the Reflection Module\n",
    "\n",
    "```python\n",
    "improved_q = reflect_and_improve(question, answer)\n",
    "print(\"Improved Question:\\n\", improved_q)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Compare and Re-run\n",
    "\n",
    "1. Run `get_answer(improved_q)` and compare the new answer to the original.\n",
    "2. Discuss:\n",
    "\n",
    "   * How did refining the question change the response?\n",
    "   * What elements of question design led to a more informative answer?\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Extension Ideas\n",
    "\n",
    "* Automate multiple reflection rounds until answer quality stops improving.\n",
    "* Add metrics to evaluate answer completeness or relevance.\n",
    "* Integrate into a web app or chat interface for live question debugging.\n",
    "\n",
    "**End of Lab**\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Demo: Selfâ€‘Reflecting AI Agent\n",
    "\n",
    "In this section, you'll build an AI agent that not only answers questions but also reflects on its own responses to iteratively improve.\n",
    "\n",
    "### 7.1 Agent Design\n",
    "\n",
    "1. **Answer Step**: Agent generates an answer with chain-of-thought.\n",
    "2. **Reflection Step**: Agent critiques its own answer for clarity and completeness.\n",
    "3. **Revision Step**: Agent refines its answer based on the critique.\n",
    "\n",
    "### 7.2 Implementation\n",
    "\n",
    "```python\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def self_reflecting_answer(question: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    # Step 1: Generate initial answer\n",
    "    ans_msgs = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a thoughtful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{question}\n",
    "Let's think step by step.\"}\n",
    "    ]\n",
    "    initial = client.chat.completions.create(model=model, messages=ans_msgs).choices[0].message.content\n",
    "\n",
    "    # Step 2: Reflect on the answer\n",
    "    ref_msgs = [\n",
    "        {\"role\": \"system\", \"content\": \"You critique your own answer for clarity and completeness.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"I answered: \\\"{initial}\\\". Provide a critique and suggest improvements.\"}\n",
    "    ]\n",
    "    reflection = client.chat.completions.create(model=model, messages=ref_msgs).choices[0].message.content\n",
    "\n",
    "    # Step 3: Revise the answer\n",
    "    rev_msgs = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that refines answers based on feedback.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Original answer: \\\"{initial}\\\"\n",
    "Critique: \\\"{reflection}\\\"\n",
    "Please provide a revised, improved answer.\"}\n",
    "    ]\n",
    "    revised = client.chat.completions.create(model=model, messages=rev_msgs).choices[0].message.content\n",
    "    return revised\n",
    "\n",
    "# Demo usage\n",
    "question = \"Explain the importance of data normalization in machine learning.\"\n",
    "final_answer = self_reflecting_answer(question)\n",
    "print(\"Final Revised Answer:\n",
    "\", final_answer)\n",
    "```\n",
    "\n",
    "### 7.3 Observations\n",
    "\n",
    "* **Compare**: Initial vs. final answers.\n",
    "* **Discuss**: How reflection improved accuracy, depth, or clarity.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Lab**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40dd179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb4664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "model_name = \"gpt-4.1\"    \n",
    "\n",
    "# openai_client = OpenAI(api_key=os.environ.get(\"OPENTYPHOON_API_KEY\"),base_url=\"https://api.opentyphoon.ai/v1\")\n",
    "# model_name = \"typhoon-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160eef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\\ nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Basic answer function using chain-of-thought prompt\n",
    "def get_answer(question: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that thinks step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{question}\\nLet's think step by step.\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa4a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_and_improve(question: str, answer: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    reflect_prompt = (\n",
    "        f\"I asked: \\\"{question}\\\" and got this answer: \\\"{answer}\\\". \"\n",
    "        \"Suggest a clearer or more specific version of my question to get an even better answer.\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that improves user questions.\"},\n",
    "        {\"role\": \"user\", \"content\": reflect_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2704b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How would you design a testing framework for an AI-driven medical diagnosis system intended for rare diseases?\",\n",
    "    \"What metrics would you propose to evaluate the fairness of a hiring algorithm trained on historical HR data?\",\n",
    "    \"How can you test the robustness of a self-driving carâ€™s perception module under extreme weather conditions?\",\n",
    "    \"Describe an approach to validate the security of an AI-powered financial trading bot against adversarial inputs.\",\n",
    "    \"How would you simulate and test task allocation in a swarm robotics system with dynamic network topologies?\",\n",
    "    \"Propose a method to measure the interpretability of a black-box deep learning model used for legal decision support.\",\n",
    "    \"What strategy would you use to continuously monitor and test an AI recommendation engine for drift in user preferences over time?\",\n",
    "    \"How can you design experiments to test real-time latency guarantees in an AI-based emergency response coordination platform?\",\n",
    "    \"Suggest a testing plan for an adaptive educational tutor AI that personalizes content based on student engagement metrics?\",\n",
    "    \"How would you verify the reliability of a distributed sensor network AI system deployed for environmental monitoring in remote regions?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b9d316e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Answer:\n",
      " Of course! Here's a step-by-step approach to testing the robustness of a self-driving car's perception module under extreme weather conditions:\n",
      "\n",
      "1. **Define Extreme Weather Conditions**: First, clearly define what extreme weather conditions you want to test - this could include heavy rain, snow, fog, strong winds, etc.\n",
      "\n",
      "2. **Create Test Scenarios**: Develop a set of test scenarios that mimic these extreme weather conditions. For example, simulate heavy rain by using water sprays or simulate fog with smoke machines.\n",
      "\n",
      "3. **Test Data Collection**: Collect real-world data of these extreme weather conditions to use during testing. This can include images, videos, Lidar scans, and radar data.\n",
      "\n",
      "4. **Test in Controlled Environment**: Initially, conduct tests in a controlled environment such as a closed test track or a simulation environment where you can safely replicate extreme weather conditions.\n",
      "\n",
      "5. **Observe System Performance**: Monitor how the perception module of the self-driving car performs under each extreme weather scenario. Note any issues or limitations encountered.\n",
      "\n",
      "6. **Iterate and Improve**: Based on the results of the tests, iterate on the perception module's design and algorithms to improve its performance under extreme weather conditions.\n",
      "\n",
      "7. **Real-World Testing**: Once improvements are made, conduct real-world testing on public roads under controlled conditions to further validate the robustness of the perception module.\n",
      "\n",
      "8. **Continuous Testing**: Regularly test and validate the perception module under various extreme weather conditions to ensure consistent performance and reliability.\n",
      "\n",
      "By following these steps, you can systematically evaluate and enhance the robustness of a self-driving car's perception module under extreme weather conditions.\n"
     ]
    }
   ],
   "source": [
    "question = questions[2]  # Example question\n",
    "answer = get_answer(question)\n",
    "print(\"Original Answer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e22a121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Question:\n",
      " How can one effectively assess the robustness of a self-driving car's perception module in extreme weather conditions through testing methods and scenarios?\n"
     ]
    }
   ],
   "source": [
    "improved_q = reflect_and_improve(question, answer)\n",
    "print(\"Improved Question:\\n\", improved_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e0279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
