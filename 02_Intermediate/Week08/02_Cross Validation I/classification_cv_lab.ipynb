{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entry-Level Classification Lab: Cross-Validation & Hyperparameter Search (No Pipelines)\n",
        "\n",
        "Welcome. In this lab you will practice **classification** with **hyperparameter search** using four validation strategies:\n",
        "\n",
        "1. **Train/Test split** (with a tiny validation split taken from the training set)\n",
        "2. **K-Fold**\n",
        "3. **Stratified K-Fold**\n",
        "4. **Group K-Fold**\n",
        "\n",
        "You will apply all four strategies to **three datasets**: **Iris**, **Wine**, and **Breast Cancer**.  \n",
        "For simplicity and clarity, we use a single model family: **DecisionTreeClassifier**.  \n",
        "You will see **explicit split loops** and **no pipelines**, to keep everything transparent and beginner-friendly.\n",
        "\n",
        "> Note: For Group K-Fold we simulate groups from the row indices so that samples from the same “group” never end up in both train and validation within a fold.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What you'll learn\n",
        "- How to perform a simple hyperparameter search with a **train/test split** plus a small validation set.\n",
        "- How to do the same search using **K-Fold**, **Stratified K-Fold**, and **Group K-Fold**.\n",
        "- How to read, compare, and reason about validation results.\n",
        "- Why stratification and grouping matter in practice.\n",
        "\n",
        "The code is structured step by step with comments so you can follow the thinking process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install requirements if needed in your environment:\n",
        "```bash\n",
        "pip install scikit-learn pandas numpy\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from itertools import product\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameter combinations: 16\n"
          ]
        }
      ],
      "source": [
        "# Define a small, beginner-friendly hyperparameter grid for DecisionTreeClassifier\n",
        "param_grid = {\n",
        "    \"max_depth\": [None, 3, 5, 7],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "    \"min_samples_leaf\": [1, 2]\n",
        "}\n",
        "\n",
        "# Expand to a list of dicts for easy iteration\n",
        "keys = list(param_grid.keys())\n",
        "params_list = []\n",
        "for values in product(*[param_grid[k] for k in keys]):\n",
        "    params_list.append(dict(zip(keys, values)))\n",
        "\n",
        "print(f\"Number of parameter combinations: {len(params_list)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c5deefb8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
            "{'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "{'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}\n",
            "{'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "{'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
            "{'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "{'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1}\n",
            "{'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "{'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
            "{'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "{'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}\n",
            "{'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "{'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
            "{'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "{'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1}\n",
            "{'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}\n"
          ]
        }
      ],
      "source": [
        "# display parameter  in params_list\n",
        "for param in params_list:\n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scoring\n",
        "We will use **accuracy** for simplicity. For each split method and each parameter setting, we compute validation accuracy and then keep the best-performing parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset: Iris\n",
        "\n",
        "We will load the Iris dataset into a Pandas DataFrame for clarity, and then apply the four validation strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (150, 4)\n",
            "y shape: (150,)\n",
            "Target classes and counts:\n",
            " target\n",
            "0    50\n",
            "1    50\n",
            "2    50\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load Iris dataset\n",
        "data = datasets.load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names if hasattr(data, \"feature_names\") else [f\"feature_{i}\" for i in range(data.data.shape[1])])\n",
        "y = pd.Series(data.target, name=\"target\")\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Target classes and counts:\\n\", y.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "edd96274",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "1aaa1787",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "564    0\n",
              "565    0\n",
              "566    0\n",
              "567    0\n",
              "568    1\n",
              "Name: target, Length: 569, dtype: int64"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Train/Test split with a small validation set\n",
        "\n",
        "We first make a **single** train/test split. Then we carve out a **validation** subset from the training data to pick hyperparameters. Finally, we retrain on the full training set using the best params and evaluate once on the held-out test set.\n",
        "\n",
        "We keep the splitting lines in the requested style.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (Train/Test with validation): {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1} | Val Acc: 0.9333\n",
            "Test Accuracy (best params): 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Train/Test split (requested style)\n",
        "# ------------------------------------------------------\n",
        "# Style like:\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# ------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Make a small validation split from the training set (60/20/20 overall)\n",
        "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "best_params_tt = None\n",
        "best_val_acc_tt = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    model = DecisionTreeClassifier(random_state=42, **params)\n",
        "    model.fit(X_train_sub, y_train_sub)\n",
        "    val_pred = model.predict(X_val)\n",
        "    val_acc = accuracy_score(y_val, val_pred)\n",
        "    if val_acc > best_val_acc_tt:\n",
        "        best_val_acc_tt = val_acc\n",
        "        best_params_tt = params\n",
        "\n",
        "print(f\"Best params (Train/Test with validation): {best_params_tt} | Val Acc: {best_val_acc_tt:.4f}\")\n",
        "\n",
        "# Retrain on full training set with best params; evaluate on the test set\n",
        "final_model_tt = DecisionTreeClassifier(random_state=42, **best_params_tt)\n",
        "final_model_tt.fit(X_train, y_train)\n",
        "test_pred = final_model_tt.predict(X_test)\n",
        "test_acc_tt = accuracy_score(y_test, test_pred)\n",
        "print(f\"Test Accuracy (best params): {test_acc_tt:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) K-Fold cross-validation hyperparameter search\n",
        "\n",
        "Here we use **KFold** and explicitly loop through folds in the requested style.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (KFold): {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1} | Mean CV Acc: 0.9533\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_params_kf = None\n",
        "best_cv_acc_kf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    fold = 0\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        fold += 1\n",
        "        # Requested style:\n",
        "        # y_train = y.iloc[train_index]\n",
        "        # y_test  = y.iloc[test_index]\n",
        "        X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_kf:\n",
        "        best_cv_acc_kf = mean_acc\n",
        "        best_params_kf = params\n",
        "\n",
        "print(f\"Best params (KFold): {best_params_kf} | Mean CV Acc: {best_cv_acc_kf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Stratified K-Fold cross-validation hyperparameter search\n",
        "\n",
        "For classification, **StratifiedKFold** keeps class proportions similar in every fold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (StratifiedKFold): {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1} | Mean CV Acc: 0.9600\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_params_skf = None\n",
        "best_cv_acc_skf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        # Requested style:\n",
        "        # for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        #     y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_skf:\n",
        "        best_cv_acc_skf = mean_acc\n",
        "        best_params_skf = params\n",
        "\n",
        "print(f\"Best params (StratifiedKFold): {best_params_skf} | Mean CV Acc: {best_cv_acc_skf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Group K-Fold cross-validation hyperparameter search\n",
        "\n",
        "**GroupKFold** ensures that the same group never appears in both train and validation within the same fold.  \n",
        "These toy datasets don't come with groups, so we **simulate** them by assigning every few consecutive rows to the same group.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (GroupKFold): {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1} | Mean CV Acc: 0.9400\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# Simulate groups so that samples that share a group never leak across folds\n",
        "# Ensure there are at least as many groups as folds\n",
        "group_size = 3  # tweakable\n",
        "groups = np.arange(len(X)) // group_size\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "best_params_gkf = None\n",
        "best_cv_acc_gkf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups), start=1):\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_gkf:\n",
        "        best_cv_acc_gkf = mean_acc\n",
        "        best_params_gkf = params\n",
        "\n",
        "print(f\"Best params (GroupKFold): {best_params_gkf} | Mean CV Acc: {best_cv_acc_gkf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>best_params</th>\n",
              "      <th>score</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train/Test + small Val</td>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2, 'min_...</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>Validation accuracy (not test) used for model ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KFold</td>\n",
              "      <td>{'max_depth': None, 'min_samples_split': 2, 'm...</td>\n",
              "      <td>0.953333</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>StratifiedKFold</td>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2, 'min_...</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GroupKFold</td>\n",
              "      <td>{'max_depth': None, 'min_samples_split': 2, 'm...</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   method                                        best_params  \\\n",
              "0  Train/Test + small Val  {'max_depth': 3, 'min_samples_split': 2, 'min_...   \n",
              "1                   KFold  {'max_depth': None, 'min_samples_split': 2, 'm...   \n",
              "2         StratifiedKFold  {'max_depth': 3, 'min_samples_split': 2, 'min_...   \n",
              "3              GroupKFold  {'max_depth': None, 'min_samples_split': 2, 'm...   \n",
              "\n",
              "      score                                               note  \n",
              "0  0.933333  Validation accuracy (not test) used for model ...  \n",
              "1  0.953333                                   Mean CV accuracy  \n",
              "2  0.960000                                   Mean CV accuracy  \n",
              "3  0.940000                                   Mean CV accuracy  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary of best results for this dataset\n",
        "summary_rows = [\n",
        "    {\"method\": \"Train/Test + small Val\", \"best_params\": best_params_tt, \"score\": float(best_val_acc_tt), \"note\": \"Validation accuracy (not test) used for model selection\"},\n",
        "    {\"method\": \"KFold\", \"best_params\": best_params_kf, \"score\": float(best_cv_acc_kf), \"note\": \"Mean CV accuracy\"},\n",
        "    {\"method\": \"StratifiedKFold\", \"best_params\": best_params_skf, \"score\": float(best_cv_acc_skf), \"note\": \"Mean CV accuracy\"},\n",
        "    {\"method\": \"GroupKFold\", \"best_params\": best_params_gkf, \"score\": float(best_cv_acc_gkf), \"note\": \"Mean CV accuracy\"},\n",
        "]\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips\n",
        "- On **small datasets**, many parameter settings will look similar. That's normal.\n",
        "- **StratifiedKFold** is usually better than plain KFold for classification, especially with imbalanced classes.\n",
        "- **GroupKFold** is essential when you have **leakage risk** across related samples (e.g., multiple records from one patient or user).\n",
        "\n",
        "Try changing the hyperparameter grid to see how results move.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset: Wine\n",
        "\n",
        "We will load the Wine dataset into a Pandas DataFrame for clarity, and then apply the four validation strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (178, 13)\n",
            "y shape: (178,)\n",
            "Target classes and counts:\n",
            " target\n",
            "0    59\n",
            "1    71\n",
            "2    48\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load Wine dataset\n",
        "data = datasets.load_wine()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names if hasattr(data, \"feature_names\") else [f\"feature_{i}\" for i in range(data.data.shape[1])])\n",
        "y = pd.Series(data.target, name=\"target\")\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Target classes and counts:\\n\", y.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Train/Test split with a small validation set\n",
        "\n",
        "We first make a **single** train/test split. Then we carve out a **validation** subset from the training data to pick hyperparameters. Finally, we retrain on the full training set using the best params and evaluate once on the held-out test set.\n",
        "\n",
        "We keep the splitting lines in the requested style.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (Train/Test with validation): {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2} | Val Acc: 0.9722\n",
            "Test Accuracy (best params): 0.9444\n"
          ]
        }
      ],
      "source": [
        "# Train/Test split (requested style)\n",
        "# ------------------------------------------------------\n",
        "# Style like:\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# ------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Make a small validation split from the training set (60/20/20 overall)\n",
        "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "best_params_tt = None\n",
        "best_val_acc_tt = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    model = DecisionTreeClassifier(random_state=42, **params)\n",
        "    model.fit(X_train_sub, y_train_sub)\n",
        "    val_pred = model.predict(X_val)\n",
        "    val_acc = accuracy_score(y_val, val_pred)\n",
        "    if val_acc > best_val_acc_tt:\n",
        "        best_val_acc_tt = val_acc\n",
        "        best_params_tt = params\n",
        "\n",
        "print(f\"Best params (Train/Test with validation): {best_params_tt} | Val Acc: {best_val_acc_tt:.4f}\")\n",
        "\n",
        "# Retrain on full training set with best params; evaluate on the test set\n",
        "final_model_tt = DecisionTreeClassifier(random_state=42, **best_params_tt)\n",
        "final_model_tt.fit(X_train, y_train)\n",
        "test_pred = final_model_tt.predict(X_test)\n",
        "test_acc_tt = accuracy_score(y_test, test_pred)\n",
        "print(f\"Test Accuracy (best params): {test_acc_tt:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) K-Fold cross-validation hyperparameter search\n",
        "\n",
        "Here we use **KFold** and explicitly loop through folds in the requested style.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (KFold): {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2} | Mean CV Acc: 0.8930\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_params_kf = None\n",
        "best_cv_acc_kf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    fold = 0\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        fold += 1\n",
        "        # Requested style:\n",
        "        # y_train = y.iloc[train_index]\n",
        "        # y_test  = y.iloc[test_index]\n",
        "        X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_kf:\n",
        "        best_cv_acc_kf = mean_acc\n",
        "        best_params_kf = params\n",
        "\n",
        "print(f\"Best params (KFold): {best_params_kf} | Mean CV Acc: {best_cv_acc_kf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Stratified K-Fold cross-validation hyperparameter search\n",
        "\n",
        "For classification, **StratifiedKFold** keeps class proportions similar in every fold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (StratifiedKFold): {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1} | Mean CV Acc: 0.8932\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_params_skf = None\n",
        "best_cv_acc_skf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        # Requested style:\n",
        "        # for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        #     y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_skf:\n",
        "        best_cv_acc_skf = mean_acc\n",
        "        best_params_skf = params\n",
        "\n",
        "print(f\"Best params (StratifiedKFold): {best_params_skf} | Mean CV Acc: {best_cv_acc_skf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Group K-Fold cross-validation hyperparameter search\n",
        "\n",
        "**GroupKFold** ensures that the same group never appears in both train and validation within the same fold.  \n",
        "These toy datasets don't come with groups, so we **simulate** them by assigning every few consecutive rows to the same group.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (GroupKFold): {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1} | Mean CV Acc: 0.9042\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# Simulate groups so that samples that share a group never leak across folds\n",
        "# Ensure there are at least as many groups as folds\n",
        "group_size = 3  # tweakable\n",
        "groups = np.arange(len(X)) // group_size\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "best_params_gkf = None\n",
        "best_cv_acc_gkf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups), start=1):\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_gkf:\n",
        "        best_cv_acc_gkf = mean_acc\n",
        "        best_params_gkf = params\n",
        "\n",
        "print(f\"Best params (GroupKFold): {best_params_gkf} | Mean CV Acc: {best_cv_acc_gkf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>best_params</th>\n",
              "      <th>score</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train/Test + small Val</td>\n",
              "      <td>{'max_depth': None, 'min_samples_split': 2, 'm...</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>Validation accuracy (not test) used for model ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KFold</td>\n",
              "      <td>{'max_depth': None, 'min_samples_split': 2, 'm...</td>\n",
              "      <td>0.893016</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>StratifiedKFold</td>\n",
              "      <td>{'max_depth': None, 'min_samples_split': 2, 'm...</td>\n",
              "      <td>0.893175</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GroupKFold</td>\n",
              "      <td>{'max_depth': None, 'min_samples_split': 2, 'm...</td>\n",
              "      <td>0.904248</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   method                                        best_params  \\\n",
              "0  Train/Test + small Val  {'max_depth': None, 'min_samples_split': 2, 'm...   \n",
              "1                   KFold  {'max_depth': None, 'min_samples_split': 2, 'm...   \n",
              "2         StratifiedKFold  {'max_depth': None, 'min_samples_split': 2, 'm...   \n",
              "3              GroupKFold  {'max_depth': None, 'min_samples_split': 2, 'm...   \n",
              "\n",
              "      score                                               note  \n",
              "0  0.972222  Validation accuracy (not test) used for model ...  \n",
              "1  0.893016                                   Mean CV accuracy  \n",
              "2  0.893175                                   Mean CV accuracy  \n",
              "3  0.904248                                   Mean CV accuracy  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary of best results for this dataset\n",
        "summary_rows = [\n",
        "    {\"method\": \"Train/Test + small Val\", \"best_params\": best_params_tt, \"score\": float(best_val_acc_tt), \"note\": \"Validation accuracy (not test) used for model selection\"},\n",
        "    {\"method\": \"KFold\", \"best_params\": best_params_kf, \"score\": float(best_cv_acc_kf), \"note\": \"Mean CV accuracy\"},\n",
        "    {\"method\": \"StratifiedKFold\", \"best_params\": best_params_skf, \"score\": float(best_cv_acc_skf), \"note\": \"Mean CV accuracy\"},\n",
        "    {\"method\": \"GroupKFold\", \"best_params\": best_params_gkf, \"score\": float(best_cv_acc_gkf), \"note\": \"Mean CV accuracy\"},\n",
        "]\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips\n",
        "- On **small datasets**, many parameter settings will look similar. That's normal.\n",
        "- **StratifiedKFold** is usually better than plain KFold for classification, especially with imbalanced classes.\n",
        "- **GroupKFold** is essential when you have **leakage risk** across related samples (e.g., multiple records from one patient or user).\n",
        "\n",
        "Try changing the hyperparameter grid to see how results move.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset: Breast Cancer\n",
        "\n",
        "We will load the Breast Cancer dataset into a Pandas DataFrame for clarity, and then apply the four validation strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (569, 30)\n",
            "y shape: (569,)\n",
            "Target classes and counts:\n",
            " target\n",
            "0    212\n",
            "1    357\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load Breast Cancer dataset\n",
        "data = datasets.load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names if hasattr(data, \"feature_names\") else [f\"feature_{i}\" for i in range(data.data.shape[1])])\n",
        "y = pd.Series(data.target, name=\"target\")\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Target classes and counts:\\n\", y.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Train/Test split with a small validation set\n",
        "\n",
        "We first make a **single** train/test split. Then we carve out a **validation** subset from the training data to pick hyperparameters. Finally, we retrain on the full training set using the best params and evaluate once on the held-out test set.\n",
        "\n",
        "We keep the splitting lines in the requested style.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (Train/Test with validation): {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1} | Val Acc: 0.9298\n",
            "Test Accuracy (best params): 0.9474\n"
          ]
        }
      ],
      "source": [
        "# Train/Test split (requested style)\n",
        "# ------------------------------------------------------\n",
        "# Style like:\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# ------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Make a small validation split from the training set (60/20/20 overall)\n",
        "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "best_params_tt = None\n",
        "best_val_acc_tt = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    model = DecisionTreeClassifier(random_state=42, **params)\n",
        "    model.fit(X_train_sub, y_train_sub)\n",
        "    val_pred = model.predict(X_val)\n",
        "    val_acc = accuracy_score(y_val, val_pred)\n",
        "    if val_acc > best_val_acc_tt:\n",
        "        best_val_acc_tt = val_acc\n",
        "        best_params_tt = params\n",
        "\n",
        "print(f\"Best params (Train/Test with validation): {best_params_tt} | Val Acc: {best_val_acc_tt:.4f}\")\n",
        "\n",
        "# Retrain on full training set with best params; evaluate on the test set\n",
        "final_model_tt = DecisionTreeClassifier(random_state=42, **best_params_tt)\n",
        "final_model_tt.fit(X_train, y_train)\n",
        "test_pred = final_model_tt.predict(X_test)\n",
        "test_acc_tt = accuracy_score(y_test, test_pred)\n",
        "print(f\"Test Accuracy (best params): {test_acc_tt:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) K-Fold cross-validation hyperparameter search\n",
        "\n",
        "Here we use **KFold** and explicitly loop through folds in the requested style.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (KFold): {'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1} | Mean CV Acc: 0.9455\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_params_kf = None\n",
        "best_cv_acc_kf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    fold = 0\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        fold += 1\n",
        "        # Requested style:\n",
        "        # y_train = y.iloc[train_index]\n",
        "        # y_test  = y.iloc[test_index]\n",
        "        X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_kf:\n",
        "        best_cv_acc_kf = mean_acc\n",
        "        best_params_kf = params\n",
        "\n",
        "print(f\"Best params (KFold): {best_params_kf} | Mean CV Acc: {best_cv_acc_kf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Stratified K-Fold cross-validation hyperparameter search\n",
        "\n",
        "For classification, **StratifiedKFold** keeps class proportions similar in every fold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (StratifiedKFold): {'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1} | Mean CV Acc: 0.9280\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_params_skf = None\n",
        "best_cv_acc_skf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        # Requested style:\n",
        "        # for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        #     y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_skf:\n",
        "        best_cv_acc_skf = mean_acc\n",
        "        best_params_skf = params\n",
        "\n",
        "print(f\"Best params (StratifiedKFold): {best_params_skf} | Mean CV Acc: {best_cv_acc_skf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Group K-Fold cross-validation hyperparameter search\n",
        "\n",
        "**GroupKFold** ensures that the same group never appears in both train and validation within the same fold.  \n",
        "These toy datasets don't come with groups, so we **simulate** them by assigning every few consecutive rows to the same group.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (GroupKFold): {'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2} | Mean CV Acc: 0.9279\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# Simulate groups so that samples that share a group never leak across folds\n",
        "# Ensure there are at least as many groups as folds\n",
        "group_size = 3  # tweakable\n",
        "groups = np.arange(len(X)) // group_size\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "best_params_gkf = None\n",
        "best_cv_acc_gkf = -1.0\n",
        "\n",
        "for params in params_list:\n",
        "    fold_accs = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups), start=1):\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = DecisionTreeClassifier(random_state=42, **params)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_valid)\n",
        "        acc = accuracy_score(y_valid, pred)\n",
        "        fold_accs.append(acc)\n",
        "    mean_acc = float(np.mean(fold_accs))\n",
        "    if mean_acc > best_cv_acc_gkf:\n",
        "        best_cv_acc_gkf = mean_acc\n",
        "        best_params_gkf = params\n",
        "\n",
        "print(f\"Best params (GroupKFold): {best_params_gkf} | Mean CV Acc: {best_cv_acc_gkf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>best_params</th>\n",
              "      <th>score</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train/Test + small Val</td>\n",
              "      <td>{'max_depth': None, 'min_samples_split': 2, 'm...</td>\n",
              "      <td>0.929825</td>\n",
              "      <td>Validation accuracy (not test) used for model ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KFold</td>\n",
              "      <td>{'max_depth': 5, 'min_samples_split': 5, 'min_...</td>\n",
              "      <td>0.945521</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>StratifiedKFold</td>\n",
              "      <td>{'max_depth': 5, 'min_samples_split': 2, 'min_...</td>\n",
              "      <td>0.927993</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GroupKFold</td>\n",
              "      <td>{'max_depth': 5, 'min_samples_split': 5, 'min_...</td>\n",
              "      <td>0.927899</td>\n",
              "      <td>Mean CV accuracy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   method                                        best_params  \\\n",
              "0  Train/Test + small Val  {'max_depth': None, 'min_samples_split': 2, 'm...   \n",
              "1                   KFold  {'max_depth': 5, 'min_samples_split': 5, 'min_...   \n",
              "2         StratifiedKFold  {'max_depth': 5, 'min_samples_split': 2, 'min_...   \n",
              "3              GroupKFold  {'max_depth': 5, 'min_samples_split': 5, 'min_...   \n",
              "\n",
              "      score                                               note  \n",
              "0  0.929825  Validation accuracy (not test) used for model ...  \n",
              "1  0.945521                                   Mean CV accuracy  \n",
              "2  0.927993                                   Mean CV accuracy  \n",
              "3  0.927899                                   Mean CV accuracy  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary of best results for this dataset\n",
        "summary_rows = [\n",
        "    {\"method\": \"Train/Test + small Val\", \"best_params\": best_params_tt, \"score\": float(best_val_acc_tt), \"note\": \"Validation accuracy (not test) used for model selection\"},\n",
        "    {\"method\": \"KFold\", \"best_params\": best_params_kf, \"score\": float(best_cv_acc_kf), \"note\": \"Mean CV accuracy\"},\n",
        "    {\"method\": \"StratifiedKFold\", \"best_params\": best_params_skf, \"score\": float(best_cv_acc_skf), \"note\": \"Mean CV accuracy\"},\n",
        "    {\"method\": \"GroupKFold\", \"best_params\": best_params_gkf, \"score\": float(best_cv_acc_gkf), \"note\": \"Mean CV accuracy\"},\n",
        "]\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips\n",
        "- On **small datasets**, many parameter settings will look similar. That's normal.\n",
        "- **StratifiedKFold** is usually better than plain KFold for classification, especially with imbalanced classes.\n",
        "- **GroupKFold** is essential when you have **leakage risk** across related samples (e.g., multiple records from one patient or user).\n",
        "\n",
        "Try changing the hyperparameter grid to see how results move.\n"
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "Generated by GPT-5 Pro"
      }
    ],
    "description": "Entry-level lab: hyperparameter search with Train/Test, K-Fold, Stratified K-Fold, and Group K-Fold on multiple datasets without pipelines.",
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
