# ğŸ“‘ Teaching Slides: Grid Search (Easy-to-Understand Version)

---

## **Slide 1 â€“ Introduction to Grid Search**

ğŸ” **What is Grid Search?**
A technique to find the **best Hyperparameters** by trying every possible value in a â€œgridâ€.

âš™ï¸ **What are Hyperparameters?**
Values that must be **set manually before training** (cannot be learned from data).

* KNN â†’ `n_neighbors`
* Decision Tree â†’ `max_depth`
* SVM â†’ `C`, `gamma`
* Neural Network â†’ learning rate, hidden layers, batch size

â­ **Why are they important?**

* Correct choice âœ… â†’ Higher accuracy
* Wrong choice âŒ â†’ Underfitting / Overfitting

ğŸ’¡ **Analogy:** Like choosing a recipe. Good ingredients = tasty food, wrong ingredients = bad taste.

---

## **Slide 2 â€“ Why Do We Need Grid Search?**

ğŸš« **Problems with guessing values**

1. **Parameters matter a lot** ğŸ¯

   * Shallow tree â†’ Underfitting
   * Deep tree â†’ Overfitting

2. **Guessing is unreliable** âŒ

   * Logistic Regression:

     * `C=1` â†’ Accuracy = 70%
     * `C=100` â†’ Accuracy = 85% ğŸ¯
   * If we never test `C=100`, we miss the best result.

3. **Grid Search = Systematic approach** âœ”

   * Tries all combinations
   * Ensures best option is found
   * No risk of skipping good values

ğŸ‘‰ From â€œguessingâ€ â†’ To **scientific searching**

---

## **Slide 3 â€“ How Grid Search Works**

ğŸ“ **Main Steps**

1ï¸âƒ£ Define parameter grid

* SVM: `C=[0.1,1,10]`, `gamma=[0.01,0.1]`
* Decision Tree: `max_depth=[3,5,7]`

2ï¸âƒ£ Try all combinations

* SVM â†’ 3Ã—2 = 6 models
* Tree â†’ 3Ã—3 = 9 models

3ï¸âƒ£ Train + Evaluate each

* Tree (depth=7, split=10) â†’ Acc=86% âœ…

4ï¸âƒ£ Pick the best result

* Best SVM = `C=10, gamma=0.01`

---

## **Slide 4 â€“ Example in Scikit-Learn**

```python
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

param_grid = {'C':[0.1,1,10], 'gamma':[0.01,0.1], 'kernel':['rbf']}
model = SVC()

grid = GridSearchCV(model, param_grid, cv=5)
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)
```

ğŸ‘‰ The program tests all values and reports the **best combination automatically**.

---

## **Slide 5 â€“ Key Takeaways**

ğŸ“Œ **Remember this**

* Grid Search = systematic way to find the **best Hyperparameters**
* Tests all values â†’ picks the best
* Works with many models (SVM, KNN, Decision Tree, Logistic Regression)
* Usually combined with **Cross-Validation**
* Prevents random guessing â†’ increases accuracy

ğŸ¯ **Shortcut memory:**
â€œGrid Search = Try every value â†’ Get the best answerâ€

