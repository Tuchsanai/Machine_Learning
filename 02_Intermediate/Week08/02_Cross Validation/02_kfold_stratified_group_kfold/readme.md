
# à¸•à¸²à¸£à¸²à¸‡à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š: à¹€à¸¥à¸·à¸­à¸à¸§à¸´à¸˜à¸µà¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸¥à¸±à¸à¸©à¸“à¸° Data

| à¸§à¸´à¸˜à¸µà¹à¸šà¹ˆà¸‡                                | à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸šà¹„à¸«à¸™                                                                                                       | à¹€à¸«à¸•à¸¸à¸œà¸¥à¸«à¸¥à¸±à¸                                                   | à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸°à¹€à¸¡à¸·à¹ˆà¸­                                                     | à¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸/à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸                                                         |
| --------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------ | ----------------------------------------------------------------- | ------------------------------------------------------------------------- |
| **train\_test\_split (à¸ªà¸¸à¹ˆà¸¡à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§)** | à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ **IID** (à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸­à¸´à¸ªà¸£à¸°à¸•à¹ˆà¸­à¸à¸±à¸™), à¸„à¸¥à¸²à¸ªà¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸ªà¸¡à¸”à¸¸à¸¥, **à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸‹à¹‰à¸³à¸‚à¸­à¸‡à¸«à¸™à¹ˆà¸§à¸¢à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™** (à¹€à¸Šà¹ˆà¸™ à¸„à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™/à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™) | à¹€à¸£à¹‡à¸§ à¹€à¸£à¸µà¸¢à¸šà¸‡à¹ˆà¸²à¸¢ à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¹€à¸¡à¸·à¹ˆà¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸²à¸à¹à¸¥à¸°à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§à¸”à¸µ           | à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ **à¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥à¸¡à¸²à¸** / à¸¡à¸µ **à¸à¸¥à¸¸à¹ˆà¸¡ (leakage)** / à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸        | à¸–à¹‰à¸²à¸ˆà¸³à¹€à¸›à¹‡à¸™à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ `stratify=y` à¸ªà¸³à¸«à¸£à¸±à¸š classification                        |
| **K-Fold**                              | à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ IID, à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸-à¸à¸¥à¸²à¸‡, à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ **à¸›à¸£à¸°à¹€à¸¡à¸´à¸™/à¸ˆà¸¹à¸™à¹„à¸®à¹€à¸›à¸­à¸£à¹Œà¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œ** à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸ªà¸–à¸µà¸¢à¸£                                           | à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸œà¸¥à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢à¸žà¸±à¸š à¸¥à¸”à¸„à¸§à¸²à¸¡à¹à¸›à¸£à¸›à¸£à¸§à¸™à¸ˆà¸²à¸à¸à¸²à¸£à¸ªà¸¸à¹ˆà¸¡à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§         | à¸„à¸¥à¸²à¸ªà¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥à¸¡à¸²à¸, à¸¡à¸µ **à¸à¸¥à¸¸à¹ˆà¸¡à¸‹à¹‰à¸³** à¹ƒà¸™à¸„à¸™/à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡/à¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™            | à¸–à¹‰à¸²à¸„à¸¥à¸²à¸ªà¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥ â†’ à¹ƒà¸Šà¹‰ **Stratified K-Fold**                               |
| **Stratified K-Fold**                   | **Classification à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥** (binary/multi-class), à¸•à¹‰à¸­à¸‡à¸£à¸±à¸à¸©à¸²à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸„à¸¥à¸²à¸ªà¹ƒà¸™à¸—à¸¸à¸à¸žà¸±à¸š                                          | à¸£à¸±à¸à¸©à¸²à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸„à¸¥à¸²à¸ªà¸—à¸¸à¸à¸žà¸±à¸š à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸¡à¸•à¸£à¸´à¸à¹„à¸¡à¹ˆà¸¥à¸³à¹€à¸­à¸µà¸¢à¸‡                 | **Regression** (à¹ƒà¸Šà¹‰à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸•à¸£à¸‡ à¹†), **à¸¡à¸±à¸¥à¸•à¸´à¹€à¸¥à¹€à¸šà¸¥** (à¸•à¹‰à¸­à¸‡à¹€à¸—à¸„à¸™à¸´à¸„à¸žà¸´à¹€à¸¨à¸©) | à¸£à¸µà¹€à¸à¸£à¸ªà¸Šà¸±à¸™à¸—à¸³à¹à¸šà¸š **stratify-à¸šà¸™-bins** à¹„à¸”à¹‰ (à¸ˆà¸±à¸” bin à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸à¹ˆà¸­à¸™)            |
| **Group K-Fold**                        | à¸¡à¸µ **à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸•à¹ˆà¸­à¸«à¸™à¹ˆà¸§à¸¢à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™** (à¸œà¸¹à¹‰à¸›à¹ˆà¸§à¸¢/à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰/à¸­à¸¸à¸›à¸à¸£à¸“à¹Œ/à¸œà¸¹à¹‰à¸žà¸¹à¸”/à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²/à¹€à¸‹à¸ªà¸Šà¸±à¸™) à¹à¸¥à¸°à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸±à¸™ leakage                   | à¸à¸±à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸­à¸‡à¸à¸¥à¸¸à¹ˆà¸¡à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¹„à¸›à¸­à¸¢à¸¹à¹ˆà¸—à¸±à¹‰à¸‡ train à¹à¸¥à¸° val/test | à¹„à¸¡à¹ˆà¸¡à¸µà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸à¸¥à¸¸à¹ˆà¸¡à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸«à¸£à¸·à¸­à¸ˆà¸³à¸™à¸§à¸™à¸à¸¥à¸¸à¹ˆà¸¡à¸™à¹‰à¸­à¸¢à¹€à¸à¸´à¸™                  | à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™ **à¸­à¸™à¸¸à¸à¸£à¸¡à¹€à¸§à¸¥à¸²** à¸„à¸§à¸£à¹ƒà¸Šà¹‰ **TimeSeriesSplit** (à¸™à¸­à¸à¹€à¸«à¸™à¸·à¸­à¸ˆà¸²à¸ 4 à¸§à¸´à¸˜à¸µà¸™à¸µà¹‰) |

> à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸‡à¸²à¸™à¸­à¸™à¸¸à¸à¸£à¸¡à¹€à¸§à¸¥à¸²/à¸•à¸²à¸¡à¸¥à¸³à¸”à¸±à¸š (time dependency) à¸„à¸§à¸£à¹ƒà¸Šà¹‰ **TimeSeriesSplit** à¸«à¸£à¸·à¸­à¸§à¸´à¸˜à¸µ holdout à¸•à¸²à¸¡à¹€à¸§à¸¥à¸² à¹„à¸¡à¹ˆà¸„à¸§à¸£à¸ªà¸¸à¹ˆà¸¡à¸ªà¸¥à¸±à¸šà¸¥à¸³à¸”à¸±à¸š

---

# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ â€œà¸›à¸£à¸°à¹€à¸ à¸— Dataâ€ à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¹à¸•à¹ˆà¸¥à¸°à¸§à¸´à¸˜à¸µ (5â€“8 à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡/à¸§à¸´à¸˜à¸µ à¸žà¸£à¹‰à¸­à¸¡à¹€à¸«à¸•à¸¸à¸œà¸¥)

## 1) train\_test\_split (à¸ªà¸¸à¹ˆà¸¡à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§ + à¸­à¸²à¸ˆ `stratify=y` à¹€à¸¡à¸·à¹ˆà¸­à¸ˆà¸³à¹€à¸›à¹‡à¸™)

1. **Ames / King County House Prices (à¸£à¸µà¹€à¸à¸£à¸ªà¸Šà¸±à¸™, à¸«à¸™à¸¶à¹ˆà¸‡à¹à¸–à¸§à¸•à¹ˆà¸­à¸šà¹‰à¸²à¸™)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸­à¸´à¸ªà¸£à¸° à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸™/à¸šà¹‰à¸²à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¸‹à¹‰à¸³à¸«à¸¥à¸²à¸¢à¹à¸–à¸§ à¹à¸¥à¸°à¸„à¸¥à¸²à¸ª/à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸±à¸à¸©à¸²à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸žà¸´à¹€à¸¨à¸© â†’ à¸ªà¸¸à¹ˆà¸¡à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­
   **à¸£à¸°à¸§à¸±à¸‡:** à¸–à¹‰à¸²à¸¡à¸µà¸šà¹‰à¸²à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¸„à¸™à¸¥à¸°à¸šà¸±à¸™à¸—à¸¶à¸ à¸«à¸£à¸·à¸­à¸¡à¸µà¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²/à¸¢à¹ˆà¸²à¸™à¸à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸à¸´à¸” leakage à¹ƒà¸«à¹‰à¸žà¸´à¸ˆà¸²à¸£à¸“à¸² Group/Time split

2. **à¸•à¸²à¸£à¸²à¸‡à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸—à¸²à¸‡à¹€à¸„à¸¡à¸µà¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸¥à¸à¸¸à¸¥ (QSAR) à¸—à¸µà¹ˆà¸ªà¸¸à¹ˆà¸¡à¸„à¸¥à¸°à¹‚à¸¡à¹€à¸¥à¸à¸¸à¸¥à¸­à¸´à¸ªà¸£à¸°**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¹‚à¸¡à¹€à¸¥à¸à¸¸à¸¥à¹€à¸›à¹‡à¸™à¸«à¸™à¹ˆà¸§à¸¢à¸­à¸´à¸ªà¸£à¸° (à¹„à¸¡à¹ˆà¸¡à¸µà¸«à¸¥à¸²à¸¢à¹à¸–à¸§à¸•à¹ˆà¸­à¹‚à¸¡à¹€à¸¥à¸à¸¸à¸¥) â†’ à¸ªà¸¸à¹ˆà¸¡à¹„à¸”à¹‰
   **à¸£à¸°à¸§à¸±à¸‡:** à¸–à¹‰à¸²à¸¡à¸µ â€œà¸Šà¸¸à¸”à¸­à¸™à¸¸à¸žà¸±à¸™à¸˜à¹Œ/à¸•à¸£à¸°à¸à¸¹à¸¥à¹‚à¸¡à¹€à¸¥à¸à¸¸à¸¥â€ à¹ƒà¸à¸¥à¹‰à¸à¸±à¸™à¸¡à¸²à¸ à¸­à¸²à¸ˆà¸žà¸´à¸ˆà¸²à¸£à¸“à¸² Group à¸•à¸²à¸¡à¸•à¸£à¸°à¸à¸¹à¸¥à¹€à¸žà¸·à¹ˆà¸­à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£ generalize

3. **à¸ à¸²à¸žà¸–à¹ˆà¸²à¸¢à¸§à¸±à¸•à¸–à¸¸à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸šà¸¸à¸„à¸„à¸¥/à¹„à¸­à¸”à¸µà¸‹à¹‰à¸³ (balanced classes)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸­à¸´à¸ªà¸£à¸° à¸„à¸¥à¸²à¸ªà¸ªà¸¡à¸”à¸¸à¸¥ â†’ à¸ªà¸¸à¹ˆà¸¡à¹€à¸£à¹‡à¸§à¹à¸¥à¸°à¸žà¸­
   **à¸£à¸°à¸§à¸±à¸‡:** à¸–à¹‰à¸²à¸ à¸²à¸žà¸«à¸¥à¸²à¸¢à¸¡à¸¸à¸¡à¸‚à¸­à¸‡ â€œà¸§à¸±à¸•à¸–à¸¸à¸Šà¸´à¹‰à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™â€ â†’ à¸„à¸§à¸£ Group

4. **à¸£à¸µà¸§à¸´à¸§à¸ªà¸´à¸™à¸„à¹‰à¸²à¹à¸šà¸šà¸«à¸™à¸¶à¹ˆà¸‡à¸£à¸µà¸§à¸´à¸§à¸•à¹ˆà¸­à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰ (one-row-per-user)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¹„à¸¡à¹ˆà¸¡à¸µà¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸„à¸™à¹€à¸”à¸´à¸¡à¸‹à¹‰à¸³à¸«à¸¥à¸²à¸¢à¹à¸–à¸§ à¸¥à¸”à¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡ leakage â†’ à¸ªà¸¸à¹ˆà¸¡à¸‡à¹ˆà¸²à¸¢
   **à¸£à¸°à¸§à¸±à¸‡:** à¸–à¹‰à¸²à¸¡à¸µà¸«à¸¥à¸²à¸¢à¸£à¸µà¸§à¸´à¸§/à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰ â†’ à¹ƒà¸Šà¹‰ Group

5. **à¸œà¸¥à¸—à¸”à¸¥à¸­à¸‡ A/B à¸—à¸µà¹ˆ aggregate à¹€à¸›à¹‡à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¹à¸–à¸§à¸•à¹ˆà¸­à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰/à¸«à¸™à¹ˆà¸§à¸¢**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸«à¸™à¸¶à¹ˆà¸‡à¸•à¹ˆà¸­à¸«à¸™à¸¶à¹ˆà¸‡ à¸¥à¸”à¸à¸²à¸£à¸žà¸¶à¹ˆà¸‡à¸žà¸² â†’ à¸ªà¸¸à¹ˆà¸¡à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¹€à¸§à¸¥à¸²
   **à¸£à¸°à¸§à¸±à¸‡:** à¸–à¹‰à¸²à¹€à¸à¹‡à¸šà¸«à¸¥à¸²à¸¢à¸£à¸­à¸šà¸•à¹ˆà¸­à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™ à¹ƒà¸«à¹‰ Group à¸•à¸²à¸¡ user

6. **à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸¥à¸²à¸ªà¸ªà¸´à¸à¹€à¸Šà¹ˆà¸™ Iris (à¸ªà¸¡à¸”à¸¸à¸¥, à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¹à¸•à¹ˆà¹€à¸”à¹‡à¸¡à¹„à¸›à¸”à¹‰à¸§à¸¢ IID)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸£à¸µà¸¢à¸šà¸‡à¹ˆà¸²à¸¢ à¹ƒà¸Šà¹‰à¸ªà¸¸à¹ˆà¸¡à¸à¹‡à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹‚à¸Ÿà¸à¸±à¸ªà¸ˆà¸¹à¸™à¸«à¸™à¸±à¸
   **à¸£à¸°à¸§à¸±à¸‡:** à¸–à¹‰à¸²à¸•à¹‰à¸­à¸‡à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¹€à¸ªà¸–à¸µà¸¢à¸£à¸ à¸²à¸žà¸‚à¸­à¸‡à¹€à¸¡à¸•à¸£à¸´à¸à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™ à¹ƒà¸«à¹‰à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ K-Fold

---

## 2) K-Fold (k=5/10 à¸•à¸²à¸¡à¸‚à¸™à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥)

1. **Iris / Wine / Breast Cancer (à¸Šà¸¸à¸”à¹€à¸¥à¹‡à¸â€“à¸à¸¥à¸²à¸‡, IID)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸œà¸¥à¸«à¸¥à¸²à¸¢à¸žà¸±à¸š à¸¥à¸”à¸„à¸§à¸²à¸¡à¸œà¸±à¸™à¸œà¸§à¸™à¸ˆà¸²à¸à¸à¸²à¸£à¸ªà¸¸à¹ˆà¸¡à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§ à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸à¸²à¸£ **à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥/à¸ˆà¸¹à¸™à¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œ**

2. **Digits (à¸ à¸²à¸žà¸•à¸±à¸§à¹€à¸¥à¸‚ 8Ã—8, \~1,800 à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡) à¹à¸šà¸šà¹„à¸¡à¹ˆà¹€à¸™à¹‰à¸™à¸šà¸²à¸¥à¸²à¸™à¸‹à¹Œà¸¡à¸²à¸**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸‚à¸™à¸²à¸”à¹„à¸¡à¹ˆà¹ƒà¸«à¸à¹ˆà¸¡à¸²à¸ à¹ƒà¸Šà¹‰ K-Fold à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¹à¸¥à¸°à¹„à¸”à¹‰à¸„à¹ˆà¸²à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸™à¸´à¹ˆà¸‡à¸‚à¸¶à¹‰à¸™

3. **à¸£à¸µà¹€à¸à¸£à¸ªà¸Šà¸±à¸™à¸„à¸¸à¸“à¸ à¸²à¸žà¹„à¸§à¸™à¹Œ/à¸£à¸²à¸„à¸²à¸šà¹‰à¸²à¸™à¸‰à¸šà¸±à¸šà¸¢à¹ˆà¸­ (à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸¡à¹ˆà¸¡à¸²à¸)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸à¸²à¸£à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸«à¸¥à¸²à¸¢à¸žà¸±à¸šà¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰ RMSE/MAE à¹€à¸ªà¸–à¸µà¸¢à¸£à¸à¸§à¹ˆà¸² holdout

4. **à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ªà¸±à¹‰à¸™à¸­à¸´à¸ªà¸£à¸° (à¹€à¸Šà¹ˆà¸™ à¸‚à¹ˆà¸²à¸§à¸žà¸²à¸”à¸«à¸±à¸§) à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™à¸‹à¹‰à¸³à¸«à¸¥à¸²à¸¢à¹à¸–à¸§**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** IID à¸ªà¸¡à¹€à¸«à¸•à¸¸à¸ªà¸¡à¸œà¸¥ à¹ƒà¸Šà¹‰ K-Fold à¹€à¸žà¸·à¹ˆà¸­à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸à¹€à¸•à¸­à¸£à¹Œà¹„à¸£à¹€à¸‹à¸­à¸£à¹Œ/à¹‚à¸¡à¹€à¸”à¸¥

5. **à¸•à¸²à¸£à¸²à¸‡à¸ªà¸¸à¸‚à¸ à¸²à¸žà¸—à¸±à¹ˆà¸§à¹„à¸› (balanced) à¹€à¸Šà¹ˆà¸™ à¸—à¸³à¸™à¸²à¸¢à¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡à¸£à¸°à¸”à¸±à¸šà¸•à¹ˆà¸³/à¸›à¸à¸•à¸´**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥à¸Šà¸±à¸” à¹ƒà¸Šà¹‰ K-Fold à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž

6. **à¸‡à¸²à¸™à¸£à¸µà¹€à¸à¸£à¸ªà¸Šà¸±à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸—à¸±à¹ˆà¸§à¹„à¸› (à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸¥à¸²à¸ª)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸„à¸¥à¸²à¸ª â†’ K-Fold à¸¡à¸²à¸•à¸£à¸à¸²à¸™

> à¸£à¸°à¸§à¸±à¸‡: à¸«à¸²à¸ **à¸„à¸¥à¸²à¸ªà¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥** à¹ƒà¸«à¹‰à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ **Stratified K-Fold** à¹€à¸žà¸·à¹ˆà¸­à¸£à¸±à¸à¸©à¸²à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¹ƒà¸™à¸—à¸¸à¸à¸žà¸±à¸š

---

## 3) Stratified K-Fold (classification à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥/à¸«à¸¥à¸²à¸¢à¸„à¸¥à¸²à¸ª)

1. **Credit Card Fraud (à¸‰à¹‰à¸­à¹‚à¸à¸‡ \~0.1â€“1%)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸•à¹‰à¸­à¸‡à¸£à¸±à¸à¸©à¸²à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™ fraud\:non-fraud à¹ƒà¸«à¹‰à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸à¸±à¸™à¹ƒà¸™à¸—à¸¸à¸à¸žà¸±à¸š à¸¡à¸´à¸‰à¸°à¸™à¸±à¹‰à¸™à¹€à¸¡à¸•à¸£à¸´à¸à¸ˆà¸°à¸œà¸±à¸™à¸œà¸§à¸™/à¸¥à¸§à¸‡à¸•à¸²

2. **Breast Cancer (malignant à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸™à¹‰à¸­à¸¢)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸£à¸±à¸à¸©à¸²à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™ malignant/benign à¹€à¸žà¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¹€à¸ªà¸–à¸µà¸¢à¸£à¸‚à¸­à¸‡ recall/ROC-AUC

3. **Churn Prediction (Positive \~10â€“30%)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¹ƒà¸«à¹‰à¹à¸•à¹ˆà¸¥à¸°à¸žà¸±à¸šà¸¡à¸µ churn/non-churn à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸ˆà¸£à¸´à¸‡ à¹€à¸žà¸·à¹ˆà¸­à¸§à¸±à¸” F1/PR-AUC à¸­à¸¢à¹ˆà¸²à¸‡à¸¢à¸¸à¸•à¸´à¸˜à¸£à¸£à¸¡

4. **Multi-class à¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥ (à¹€à¸Šà¹ˆà¸™ 5 à¸„à¸¥à¸²à¸ª à¹à¸•à¹ˆà¸šà¸²à¸‡à¸„à¸¥à¸²à¸ªà¸¡à¸µà¸™à¹‰à¸­à¸¢à¸¡à¸²à¸)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸„à¸§à¸šà¸„à¸¸à¸¡à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸—à¸¸à¸à¸„à¸¥à¸²à¸ªà¸•à¹ˆà¸­à¸žà¸±à¸š à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸žà¸±à¸šà¹ƒà¸”à¸žà¸±à¸šà¸«à¸™à¸¶à¹ˆà¸‡à¸‚à¸²à¸”à¸„à¸¥à¸²à¸ªà¸«à¸²à¸¢à¹„à¸›

5. **Defect Detection à¹ƒà¸™à¹‚à¸£à¸‡à¸‡à¸²à¸™ (à¹€à¸ªà¸µà¸¢ \~2â€“5%)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ validation à¸žà¸±à¸šà¸—à¸µà¹ˆà¹à¸—à¸šà¹„à¸¡à¹ˆà¸¡à¸µ defect à¸‹à¸¶à¹ˆà¸‡à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸¡à¸•à¸£à¸´à¸à¸ªà¸¹à¸‡à¸œà¸´à¸”à¸ˆà¸£à¸´à¸‡

6. **Star Rating (1â€“5 à¸”à¸²à¸§) à¸—à¸µà¹ˆà¸›à¸¥à¸²à¸¢à¸ªà¸¸à¸” (1/5) à¸™à¹‰à¸­à¸¢**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸£à¸±à¸à¸©à¸²à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸—à¸¸à¸à¸£à¸°à¸”à¸±à¸šà¸”à¸²à¸§à¹ƒà¸™à¸—à¸¸à¸à¸žà¸±à¸š

7. **à¸„à¸¥à¸²à¸ªà¹‚à¸£à¸„à¸«à¸¥à¸²à¸¢à¸£à¸°à¸¢à¸° (Stage Iâ€“IV) à¸—à¸µà¹ˆà¸à¸£à¸°à¸ˆà¸²à¸¢à¹„à¸¡à¹ˆà¹€à¸—à¹ˆà¸²à¸à¸±à¸™**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¹ƒà¸«à¹‰à¸—à¸¸à¸à¸£à¸°à¸¢à¸°à¸›à¸£à¸²à¸à¸à¹ƒà¸™à¸—à¸¸à¸à¸žà¸±à¸š â†’ à¸›à¸£à¸°à¹€à¸¡à¸´à¸™ macro-F1 à¹„à¸”à¹‰à¸•à¸£à¸‡à¸à¸§à¹ˆà¸²

> à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸‡à¸²à¸™à¸£à¸µà¹€à¸à¸£à¸ªà¸Šà¸±à¸™à¹ƒà¸Šà¹‰ Stratified à¹‚à¸”à¸¢à¸•à¸£à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ à¹à¸•à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸– **à¸ˆà¸±à¸” bin à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢** (à¹€à¸Šà¹ˆà¸™ quantiles) à¹à¸¥à¹‰à¸§à¸—à¸³ Stratified K-Fold à¸šà¸™ bin à¹à¸—à¸™

---

## 4) Group K-Fold (à¸à¸±à¸™ leakage à¸£à¸°à¸”à¸±à¸š â€œà¸«à¸™à¹ˆà¸§à¸¢/à¹€à¸­à¸™à¸—à¸´à¸•à¸µâ€)

1. **à¸œà¸¹à¹‰à¸›à¹ˆà¸§à¸¢à¸¡à¸µà¸«à¸¥à¸²à¸¢ visit/record à¸•à¹ˆà¸­à¸„à¸™ (Patient-level)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸–à¹‰à¸²à¸„à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¹‚à¸œà¸¥à¹ˆà¸—à¸±à¹‰à¸‡ train à¹à¸¥à¸° val à¸ˆà¸° leakage (à¹‚à¸¡à¹€à¸”à¸¥à¸ˆà¸³à¸¥à¸±à¸à¸©à¸“à¸°à¹€à¸‰à¸žà¸²à¸°à¸šà¸¸à¸„à¸„à¸¥) â†’ Group à¸•à¸²à¸¡ `patient_id`

2. **à¹€à¸ªà¸µà¸¢à¸‡à¸žà¸¹à¸”à¸«à¸¥à¸²à¸¢à¸„à¸¥à¸´à¸›à¸•à¹ˆà¸­à¸œà¸¹à¹‰à¸žà¸¹à¸” (Speaker-level)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸­à¸à¸¥à¸±à¸à¸©à¸“à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸‚à¸­à¸‡ speaker à¹ƒà¸™ train à¹à¸¥à¹‰à¸§à¹„à¸›à¸—à¸²à¸¢ val à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸„à¸™à¹€à¸”à¸´à¸¡ â†’ Group à¸•à¸²à¸¡ `speaker_id`

3. **à¸ à¸²à¸žà¸«à¸¥à¸²à¸¢à¹ƒà¸šà¸•à¹ˆà¸­ â€œà¸§à¸±à¸•à¸–à¸¸/à¸šà¸¸à¸„à¸„à¸¥â€ à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™ (Subject-level / product-level)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸«à¸¥à¸²à¸¢à¸¡à¸¸à¸¡/à¸«à¸¥à¸²à¸¢à¸ªà¸ à¸²à¸žà¹à¸ªà¸‡à¸‚à¸­à¸‡à¸§à¸±à¸•à¸–à¸¸à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™ â†’ à¸–à¹‰à¸²à¹„à¸¡à¹ˆ group à¸ˆà¸°à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸ªà¸¹à¸‡à¹€à¸à¸´à¸™à¸ˆà¸£à¸´à¸‡

4. **à¸£à¸µà¸§à¸´à¸§/à¸žà¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢à¸£à¸²à¸¢à¸à¸²à¸£à¸•à¹ˆà¸­ user (Recommender / CTR)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸à¸´à¸ˆà¸à¸£à¸£à¸¡à¸‚à¸­à¸‡ user à¹€à¸”à¸´à¸¡à¸‹à¹‰à¸³à¸«à¸¥à¸²à¸¢à¹à¸–à¸§ â†’ Group à¸•à¸²à¸¡ `user_id` (à¸«à¸£à¸·à¸­à¸—à¸”à¸¥à¸­à¸‡ `item_id` à¸«à¸²à¸à¸­à¸¢à¸²à¸à¸—à¸”à¸ªà¸­à¸š generalize à¹„à¸›à¸¢à¸±à¸‡ item à¹ƒà¸«à¸¡à¹ˆ)

5. **à¹€à¸‹à¸™à¹€à¸‹à¸­à¸£à¹Œà¸«à¸¥à¸²à¸¢à¸­à¹ˆà¸²à¸™à¸„à¹ˆà¸²à¸•à¹ˆà¸­à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡ (Machine-level)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸­à¹ˆà¸²à¸™à¸ˆà¸²à¸à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¹ƒà¸à¸¥à¹‰à¸à¸±à¸™à¸¡à¸²à¸ â†’ Group à¸•à¸²à¸¡ `machine_id` à¹€à¸žà¸·à¹ˆà¸­à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸šà¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹ƒà¸«à¸¡à¹ˆà¸ˆà¸£à¸´à¸‡ à¹†

6. **à¹€à¸­à¸à¸ªà¸²à¸£/à¹‚à¸žà¸ªà¸•à¹Œà¸«à¸¥à¸²à¸¢à¸Šà¸´à¹‰à¸™à¸•à¹ˆà¸­à¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™ (Author-level NLP)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸ªà¸³à¸™à¸§à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¸—à¸³à¹ƒà¸«à¹‰ leakage â†’ Group à¸•à¸²à¸¡ `author_id`

7. **à¸¢à¸­à¸”à¸‚à¸²à¸¢à¸£à¸²à¸¢à¸šà¸´à¸¥/à¸£à¸²à¸¢à¸à¸²à¸£à¸«à¸¥à¸²à¸¢à¸£à¸²à¸¢à¸à¸²à¸£à¸•à¹ˆà¸­à¸£à¹‰à¸²à¸™ (Store-level)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸£à¹‰à¸²à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¸¡à¸µà¸£à¸¹à¸›à¹à¸šà¸šà¹€à¸‰à¸žà¸²à¸° â†’ Group à¸•à¸²à¸¡ `store_id` à¹€à¸žà¸·à¹ˆà¸­à¸§à¸±à¸”à¸à¸²à¸£à¸¢à¹‰à¸²à¸¢à¹‚à¸¡à¹€à¸”à¸¥à¹„à¸›à¸¢à¸±à¸‡à¸£à¹‰à¸²à¸™à¹ƒà¸«à¸¡à¹ˆ

8. **à¸ à¸²à¸ž defect à¸«à¸¥à¸²à¸¢à¸ à¸²à¸žà¸•à¹ˆà¸­à¸Šà¸´à¹‰à¸™à¸‡à¸²à¸™à¹€à¸”à¸µà¸¢à¸§ (Part-level vision)**
   **à¹€à¸«à¸•à¸¸à¸œà¸¥:** à¸Šà¸´à¹‰à¸™à¸‡à¸²à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¸–à¹ˆà¸²à¸¢à¸«à¸¥à¸²à¸¢à¸¡à¸¸à¸¡ â†’ Group à¸•à¸²à¸¡ `part_id`

---

## à¸•à¸²à¸£à¸²à¸‡à¸¡à¸­à¸‡à¹€à¸£à¹‡à¸§: â€œà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œâ€ vs â€œà¸§à¸´à¸˜à¸µà¹à¸™à¸°à¸™à¸³â€

| à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œ                    | train\_test\_split | K-Fold | Stratified K-Fold | Group K-Fold |
| ------------------------------------ | :----------------: | :----: | :---------------: | :----------: |
| à¸£à¸²à¸„à¸²à¸šà¹‰à¸²à¸™ à¸«à¸™à¸¶à¹ˆà¸‡à¹à¸–à¸§à¸•à¹ˆà¸­à¸šà¹‰à¸²à¸™ (IID)       |          âœ“         |    âœ“   |                   |              |
| à¸„à¸¸à¸“à¸ à¸²à¸žà¹„à¸§à¸™à¹Œ (à¸£à¸µà¹€à¸à¸£à¸ªà¸Šà¸±à¸™, IID, à¸Šà¸¸à¸”à¹€à¸¥à¹‡à¸) |                    |    âœ“   |                   |              |
| Fraud Detection (à¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥à¸¡à¸²à¸)        |  (à¸à¸±à¸š `stratify`)  |        |         âœ“         |              |
| Breast Cancer (à¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥)             |  (à¸à¸±à¸š `stratify`)  |        |         âœ“         |              |
| à¸ à¸²à¸žà¸«à¸¥à¸²à¸¢à¸¡à¸¸à¸¡à¸•à¹ˆà¸­à¸§à¸±à¸•à¸–à¸¸à¹€à¸”à¸µà¸¢à¸§              |                    |        |                   |       âœ“      |
| à¸œà¸¹à¹‰à¸›à¹ˆà¸§à¸¢à¸«à¸¥à¸²à¸¢ visit                    |                    |        |                   |       âœ“      |
| à¸œà¸¹à¹‰à¸žà¸¹à¸”à¸«à¸¥à¸²à¸¢à¸„à¸¥à¸´à¸›à¹€à¸ªà¸µà¸¢à¸‡                  |                    |        |                   |       âœ“      |
| à¸£à¸µà¸§à¸´à¸§à¸«à¸¥à¸²à¸¢à¸£à¸²à¸¢à¸à¸²à¸£à¸•à¹ˆà¸­ user              |                    |        |                   |       âœ“      |
| à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ªà¸±à¹‰à¸™ IID à¹„à¸¡à¹ˆà¸¡à¸µà¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™à¸‹à¹‰à¸³     |          âœ“         |    âœ“   | *à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥ â†’* âœ“ |              |
| à¸£à¸µà¹€à¸à¸£à¸ªà¸Šà¸±à¸™à¸—à¸±à¹ˆà¸§à¹„à¸› (à¹„à¸¡à¹ˆà¸¡à¸µ bin/à¸à¸¥à¸¸à¹ˆà¸¡)    |          âœ“         |    âœ“   |                   |              |

---

## à¹€à¸Šà¹‡à¸„à¸à¹ˆà¸­à¸™à¹€à¸¥à¸·à¸­à¸à¸§à¸´à¸˜à¸µ (Checklist à¸ªà¸±à¹‰à¸™ à¹†)

* **à¸¡à¸µ â€œà¸«à¸¥à¸²à¸¢à¹à¸–à¸§à¸•à¹ˆà¸­à¸«à¸™à¹ˆà¸§à¸¢â€ à¹„à¸«à¸¡?** â†’ à¹ƒà¸Šà¹‰ **Group K-Fold**
* **à¹€à¸›à¹‡à¸™ Classification à¹à¸¥à¸°à¸„à¸¥à¸²à¸ªà¹„à¸¡à¹ˆà¸ªà¸¡à¸”à¸¸à¸¥?** â†’ **Stratified K-Fold** (à¸«à¸£à¸·à¸­ `train_test_split(..., stratify=y)`)
* **à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸ˆà¸¹à¸™/à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸™à¸´à¹ˆà¸‡ à¹† à¸šà¸™à¸Šà¸¸à¸”à¹€à¸¥à¹‡à¸â€“à¸à¸¥à¸²à¸‡?** â†’ **K-Fold**
* **à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸à¹ˆ, IID à¸Šà¸±à¸”, à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™?** â†’ **train\_test\_split** à¸à¹‡à¸žà¸­
* **à¸¡à¸µà¸¥à¸³à¸”à¸±à¸šà¹€à¸§à¸¥à¸²?** â†’ à¹ƒà¸Šà¹‰ **TimeSeriesSplit / split à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²** (à¸­à¸¢à¹ˆà¸²à¸ªà¸¸à¹ˆà¸¡à¸›à¸™)





---

## Slide 0 â€” Learning Goals (What youâ€™ll master)

* Why we split data and how this prevents **data leakage**
* When to use **holdâ€‘out** vs **crossâ€‘validation**
* How **Kâ€‘Fold**, **Stratified Kâ€‘Fold**, and **Group Kâ€‘Fold** differ
* Read **fold diagrams** and map them to real code
* Choose the **right splitter** for your dataset and task

---

## Slide 1 â€” Why Split at All?

**Objective:** estimate how well the model will generalize to unseen data.

* **Training set** â†’ fit model parameters
* **Validation set** â†’ tune hyperparameters (via CV)
* **Test set** â†’ final, unbiased performance estimate

**If you tune on the test set â†’ leakage â†’ overly optimistic results.**

---

## Slide 2 â€” Vocabulary & Symbols

* We label samples as **x1, x2, â€¦, xN** (and class labels as **y1, y2, â€¦**)
* **Fold** = one partition; in Kâ€‘Fold we cycle through which fold is validation.
* **Stratify** = preserve class proportions in each split.
* **Group** = all samples sharing the same entity (patient, user, houseâ€‘ID) must stay together.

---

## Slide 3 â€” Holdâ€‘Out Split with `train_test_split`

Use for quick baselines or when the dataset is large enough.

**Visual (N = 20, test\_size = 0.2):**

```
All:   x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16 x17 x18 x19 x20
Train: [ x? x? x? x? x? x? x? x? x?  x?  x?  x?  x?  x?  x?  x? ]  (80%)
Test:  [ x? x? x? x? ]                                    (20%)
```

* With `shuffle=True` (default) the composition is random; control with `random_state`.
* For **classification**, use `stratify=y` to keep class ratios similar.

**When NOT to use**: time series or grouped data â†’ use specialized splitters.

---

## Slide 4 â€” `train_test_split` (Regression, quick baseline)

```python
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
import numpy as np

X, y = load_diabetes(return_X_y=True)
Xtr, Xte, ytr, yte = train_test_split(
    X, y, test_size=0.2, random_state=42 # shuffle by default
)

model = LinearRegression().fit(Xtr, ytr)
y_pred = model.predict(Xte)
rmse = np.sqrt(mean_squared_error(yte, y_pred))
print(f"Test RMSE: {rmse:.3f}")
print(f"Test R2  : {r2_score(yte, y_pred):.3f}")
```

**Tips:**

* Use `train_size`/`test_size` to control proportions.
* Set `random_state` for reproducibility in teaching/demo.

---

## Slide 5 â€” `train_test_split` (Classification with `stratify`)

**Why?** Keeps class balance similar across train and test (critical for imbalanced data).

**Visual (binary classes A/B, \~50/50):**

```
Indices: x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16
Labels :  A  B  A  A  B  B  A  B  A   A   B   A   B   A   B   B
Train :   ~80% with A/B ratio â‰ˆ original
Test  :   ~20% with A/B ratio â‰ˆ original
```

```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

X, y = load_breast_cancer(return_X_y=True)
Xtr, Xte, ytr, yte = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

clf = LogisticRegression(max_iter=1000).fit(Xtr, ytr)
print("Accuracy:", accuracy_score(yte, clf.predict(Xte)))
```

---

## Slide 6 â€” Kâ€‘Fold Crossâ€‘Validation (Overview)

* Split data into **K** equal folds.
* Train **K times**: each time, hold out one fold as validation and train on the rest.
* Report the **mean/Â±std** of the metric across K runs.

**Why?** Uses all data for training & validation across runs â†’ more stable estimates than a single holdâ€‘out.

**Typical K**: 5 or 10.

---

## Slide 7 â€” Kâ€‘Fold (Diagram, K=5, N=20)

```
Idx :   1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
Fold:  [1][2][3][4][5][1][2][3][4][5][1][2][3][4][5][1][2][3][4][5]

Iter 1 (val=Fold 1): val = {x1,x6,x11,x16}
Iter 2 (val=Fold 2): val = {x2,x7,x12,x17}
Iter 3 (val=Fold 3): val = {x3,x8,x13,x18}
Iter 4 (val=Fold 4): val = {x4,x9,x14,x19}
Iter 5 (val=Fold 5): val = {x5,x10,x15,x20}
```

* With `shuffle=True`, fold assignment is randomized (use `random_state`).

---

## Slide 8 â€” Kâ€‘Fold (Code, regression)

```python
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import make_scorer, mean_squared_error
from sklearn.linear_model import Ridge
import numpy as np

kf = KFold(n_splits=5, shuffle=True, random_state=42)
model = Ridge(alpha=1.0)
rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)

scores = cross_val_score(model, X, y, cv=kf, scoring=rmse_scorer)
rmse = np.sqrt(-scores)  # scores are negative MSE
print("Fold RMSEs:", np.round(rmse, 3))
print("Mean Â± SD RMSE:", f"{rmse.mean():.3f} Â± {rmse.std():.3f}")
```

---

## Slide 9 â€” Stratified Kâ€‘Fold (Overview)

**For classification.** Ensures each fold has roughly the same class proportions as the full dataset.

**When to use:** imbalanced classes, small datasets, metrics sensitive to prevalence.

**Not for regression** (thereâ€™s `StratifiedKFold` only for classification; for regression see advanced methods like `StratifiedKFold` on binned targets if needed).

---

## Slide 10 â€” Stratified Kâ€‘Fold (Diagram)

Assume 16 samples, labels A/B with counts A=8, B=8.

```
Idx :     1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16
Label:    A  B  A  A  B  B  A  B  A  A  B  A  B  A  B  B

K=4 folds (each fold aims for A=2, B=2):
Fold 1:   A  B  A  B
Fold 2:   A  B  A  B
Fold 3:   A  B  A  B
Fold 4:   A  B  A  B
```

Each iteration: one fold is validation; the rest are training.

---

## Slide 11 â€” Stratified Kâ€‘Fold (Code, classification)

```python
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.linear_model import LogisticRegression

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
clf = LogisticRegression(max_iter=1000)

cv = cross_validate(
    clf, X, y, cv=skf, scoring=["accuracy", "f1_macro"], return_train_score=True
)

print("Val Accuracy:", np.round(cv["test_accuracy"], 3))
print("Val F1-macro:", np.round(cv["test_f1_macro"], 3))
print(
    f"Mean Acc: {cv['test_accuracy'].mean():.3f} Â± {cv['test_accuracy'].std():.3f} | "
    f"Mean F1m: {cv['test_f1_macro'].mean():.3f} Â± {cv['test_f1_macro'].std():.3f}"
)
```

**Tip:** Always use `shuffle=True` + `random_state` for reproducible teaching demos.

---

## Slide 12 â€” Group Kâ€‘Fold (Overview)

**Goal:** keep all samples from the same **group** entirely in **train** or **validation**, never split across.

**Useâ€‘cases:**

* Multiple records per **patient**, **user**, **household**, **product**
* Multiple images per subject/session

**Why?** If the same group leaks into both train and validation, performance is inflated.

---

## Slide 13 â€” Group Kâ€‘Fold (Diagram)

Example: 10 samples with 5 groups

```
Sample:  x1 x2 x3 x4 x5 x6 x7 x8 x9 x10
Group :  g1 g1 g2 g2 g2 g3 g3 g4 g4 g5

K=3 (one possible assignment):
Iter 1: Val groups {g1, g4} â†’ Val = {x1,x2,x8,x9}; Train = others
Iter 2: Val group  {g2}     â†’ Val = {x3,x4,x5};    Train = others
Iter 3: Val groups {g3, g5} â†’ Val = {x6,x7,x10};   Train = others
```

Groups never appear in both train and validation simultaneously.

---

## Slide 14 â€” Group Kâ€‘Fold (Code)

```python
import numpy as np
from sklearn.model_selection import GroupKFold
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

# Fake data (replace with real X, y)
N = 30
X = np.random.randn(N, 5)
y = X[:, 0] * 2.0 + np.random.randn(N)

# Create groups (e.g., 10 users, each appears 3 times)
groups = np.repeat(np.arange(10), 3)  # [0,0,0, 1,1,1, ..., 9,9,9]

model = Ridge(alpha=1.0)
gkf = GroupKFold(n_splits=5)

fold = 0
for train_idx, val_idx in gkf.split(X, y, groups=groups):
    fold += 1
    model.fit(X[train_idx], y[train_idx])
    pred = model.predict(X[val_idx])
    rmse = np.sqrt(mean_squared_error(y[val_idx], pred))
    print(f"Fold {fold}: Val RMSE = {rmse:.3f} | Val groups = {np.unique(groups[val_idx])}")
```

**Note:** Group sizes can be uneven; `GroupKFold` distributes groups across folds to balance counts of groups, not sample counts.

---

## Slide 15 â€” Grouped Holdâ€‘Out (single split) with `GroupShuffleSplit`

When you need **one train/test split** but must respect groups.

```python
from sklearn.model_selection import GroupShuffleSplit

gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_idx, test_idx = next(gss.split(X, y, groups=groups))
Xtr, Xte = X[train_idx], X[test_idx]
ytr, yte = y[train_idx], y[test_idx]
```

---

## Slide 16 â€” Visualizing Folds in Code (ASCII helper)

Use this in class to **print** fold maps your students can read.

```python
import numpy as np

def print_fold_map(indices, title=""):
    # indices: list of arrays (each one is the validation indices of that fold)
    all_idx = sorted(np.unique(np.concatenate(indices)))
    asgn = {i: None for i in all_idx}
    for f, val in enumerate(indices, start=1):
        for ix in val:
            asgn[ix] = f
    line_idx = " ".join([f"{i:>2}" for i in all_idx])
    line_fld = " ".join([f"[{asgn[i]:>1}]" for i in all_idx])
    print(title)
    print("Idx :", line_idx)
    print("Fold:", line_fld)

# Example for KFold
from sklearn.model_selection import KFold
X_dummy = np.zeros((20, 3))
kf = KFold(n_splits=5, shuffle=True, random_state=42)
val_lists = [val for _, val in kf.split(X_dummy)]
print_fold_map(val_lists, title="KFold assignment (val fold labels)")
```

This produces a map similar to Slide 7.

---

## Slide 17 â€” Choosing the Right Splitter (Cheat Sheet)

| Situation                                          | Use                                                    | Why                                     |
| -------------------------------------------------- | ------------------------------------------------------ | --------------------------------------- |
| Quick baseline, large data, no groups              | `train_test_split` (+ `stratify=y` for classification) | Fast, simple                            |
| Hyperparameter tuning (regression)                 | `KFold`                                                | Stable estimate across folds            |
| Hyperparameter tuning (classification, imbalanced) | `StratifiedKFold`                                      | Preserves class ratios                  |
| Same entity appears multiple times                 | `GroupKFold` / `GroupShuffleSplit`                     | Avoid leakage across group              |
| Timeâ€‘ordered data                                  | `TimeSeriesSplit`                                      | Respects temporal order (no lookâ€‘ahead) |

---

## Slide 18 â€” Gotchas & Best Practices

* **Always set `random_state`** when teaching/demonstrating.
* **Shuffle** before Kâ€‘Fold unless order is meaningful (e.g., time series).
* **Stratify** whenever class imbalance exists.
* For `GroupKFold`, ensure **groups align** with real leakage boundaries.
* Avoid using the **test set** for model selection; keep it sealed until final.

---

## Slide 19 â€” Miniâ€‘Labs (ready for class)

1. **Holdâ€‘Out + Stratify (Breast Cancer):**

   * Compare accuracy with & without `stratify=y` on small test\_size.
2. **Kâ€‘Fold (Diabetes):**

   * Evaluate Ridge with K=3,5,10. Discuss mean vs variance of RMSE.
3. **StratifiedKFold (Iris â†’ binary subset):**

   * Filter to two classes; compare `KFold` vs `StratifiedKFold` stability.
4. **GroupKFold (synthetic groups):**

   * Show inflated accuracy when you ignore groups vs proper GroupKFold.

---

## Slide 20 â€” Appendix: Quick Patterns

**Scoring with `cross_validate` (multiple metrics):**

```python
from sklearn.model_selection import cross_validate
from sklearn.metrics import make_scorer, f1_macro, accuracy_score

cv = cross_validate(
    clf, X, y, cv=skf,
    scoring={"acc": "accuracy", "f1m": "f1_macro"},
    return_train_score=True
)
print(cv.keys())  # dict of arrays for each metric
```

**Using splitters directly inside GridSearchCV:**

```python
from sklearn.model_selection import GridSearchCV

param_grid = {"alpha": [0.1, 1.0, 10.0]}
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
search = GridSearchCV(RidgeClassifier(), param_grid=param_grid, cv=cv)
```

---

## Slide 21 â€” Summary

* **train\_test\_split** â†’ fast baseline; use `stratify` for classification
* **Kâ€‘Fold** â†’ robust estimates; standard for regression
* **StratifiedKFold** â†’ classification with balanced folds
* **GroupKFold** â†’ prevents leakage across entities/groups
* Visualize folds to **explain** and **debug** your evaluation

ðŸŽ¯ *You can copy any code cell into a Jupyter notebook and run immediately.*
